from langgraph.graph import StateGraph
from langgraph.graph import START
from langgraph.graph import END 
from chatbot.domain.main_agent.memory import MemoryService
from chatbot.domain.main_agent.rephraser import RephraserService
from chatbot.domain.main_agent.decomposer import DecomposerService
from chatbot.domain.main_agent.sub_agent import SubAgentService
from chatbot.domain.main_agent.aggregator import AggregatorService
from chatbot.domain.main_agent.direct_answer import DirectAnswerService
from chatbot.domain.geoadmin_agent import GeoadminService
from chatbot.domain.autofill_agent import AutofillService
from chatbot.domain.profile_agent import ProfileService
from typing import Dict
import asyncio
from fastapi import Request
from functools import cached_property
from lite_llm.models import LiteLLMInput, CompletionMessage, Role
from typing_extensions import Literal
from langchain_core.runnables import RunnableLambda
from concurrent.futures import ThreadPoolExecutor
from fastapi import BackgroundTasks
from chatbot.shared.state.chatbot_state import ChatbotState 
from chatbot.shared.state.sub_agent_state import SubAgentState
from typing import Any
from base import BaseApplication
from base import BaseModel


class ChatbotApplicationInput(BaseModel):
    raw_question: str 
    user_id: str 
    conversation_id: str 
    conversation_history: list[Any]

class ChatbotApplicationOutput(BaseModel):
    raw_question: str 
    rephrased_question: str
    sub_questions: list[str]
    refined_contexts: list[str]
    answer: str 
    references: list[str]
    filled_profile_info: dict[str, Any] = {}
    detected_fields:  Dict[str, str]


class ChatbotApplication(BaseApplication):

    request: Request

    @property
    def memory_service(self) -> MemoryService:
        return MemoryService(database=self.request.app.state.database_service)
    @property
    def rephraser(self) -> RephraserService:
        return RephraserService(litellm_service=self.request.app.state.litellm_service)
    @property
    def profile_agent(self) -> ProfileService:
        return ProfileService()
    @property
    def autofill_agent(self) -> AutofillService:
        return AutofillService(litellm_service=self.request.app.state.litellm_service)

    @property
    def decomposer(self) -> DecomposerService:
        return DecomposerService(litellm_service=self.request.app.state.litellm_service)

    @cached_property
    def sub_agent(self) -> SubAgentService:
        return SubAgentService(litellm_service=self.request.app.state.litellm_service)
    
    @property
    def geoadmin_agent(self) -> GeoadminService:
        return GeoadminService()

    @property
    def aggregator(self) -> AggregatorService:
        return AggregatorService(litellm_service=self.request.app.state.litellm_service)
    
    @property
    def direct_answer(self) -> DirectAnswerService:
        return DirectAnswerService(litellm_service=self.request.app.state.litellm_service)
    
    
    # @property
    # def memory_service(self) -> MemoryService:
    #     return MemoryService()

    @property
    def nodes(self) -> dict[str, Any]:
        return {
            "conversation_history": self.memory_service.process,
            "direct_answer": self.direct_answer.process,
            "rephrase_question": self.rephraser.process,
            "decompose_question": self.decomposer.process,
            "sub_agent": self.gather_refined_contexts,
            "answer_aggregator": self.aggregator.process,
            "geoadmin_agent": self.geoadmin_agent.run,
            'autofill_agent': self.autofill_agent.process,
            'profile_agent': self.profile_agent.process,
            # "memory_retrieval": self.memory_service.retrieve_memory,
        }
    
    def route_agent(self, state: ChatbotState) -> Literal["rephrase_question", "geoadmin_agent", 'autofill_agent']:
        """
        LLM-based Router - quyáº¿t Ä‘á»‹nh routing cÃ¢u há»i Ä‘áº¿n agent phÃ¹ há»£p
        """
        PROMPT = """
        <role>
        Báº¡n lÃ  má»™t router agent trong há»‡ thá»‘ng chatbot há»— trá»£ thá»§ tá»¥c hÃ nh chÃ­nh.
        Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  phÃ¢n tÃ­ch CÃ‚U Há»I HIá»†N Táº I vÃ  routing Ä‘áº¿n agent phÃ¹ há»£p.
        </role>
        
        <instruction>
        QUAN TRá»ŒNG: PhÃ¢n tÃ­ch cÃ¢u há»i HIá»†N Táº I, nhÆ°ng cÃ³ thá»ƒ tham kháº£o context tá»« lá»‹ch sá»­ náº¿u cÃ¢u há»i hiá»‡n táº¡i cáº§n ngá»¯ cáº£nh Ä‘á»ƒ hiá»ƒu Ä‘áº§y Ä‘á»§.
        
        Vá»›i cÃ¢u há»i follow-up (nhÆ° "Tháº¿ cÃ²n X thÃ¬ sao?", "CÃ²n Y thÃ¬ tháº¿ nÃ o?"), hÃ£y xem xÃ©t ngá»¯ cáº£nh tá»« cÃ¢u há»i trÆ°á»›c Ä‘á»ƒ hiá»ƒu intent Ä‘áº§y Ä‘á»§.
        </instruction>

        <constraint>
        Quy táº¯c routing THÃ”NG MINH:
        
        1. Route Ä‘áº¿n "autofill_agent" Náº¾U:
           - CÃ¢u há»i hiá»‡n táº¡i chá»©a tá»« khÃ³a: "Ä‘iá»n form", "lÃ m Ä‘Æ¡n", "táº¡o Ä‘Æ¡n", "Ä‘iá»n thÃ´ng tin", "biá»ƒu máº«u"
           - User trá»±c tiáº¿p yÃªu cáº§u há»— trá»£ Ä‘iá»n form/Ä‘Æ¡n tá»«
           - Há»i vá» cÃ¡ch thá»©c Ä‘iá»n form cá»¥ thá»ƒ
           
        2. Route Ä‘áº¿n "geoadmin_agent" Náº¾U:
           - CÃ¢u há»i hiá»‡n táº¡i chá»©a tá»« khÃ³a Ä‘á»‹a lÃ½: "Ä‘á»‹a chá»‰", "á»Ÿ Ä‘Ã¢u", "vá»‹ trÃ­", "báº£n Ä‘á»“", "tá»a Ä‘á»™"
           - Há»i vá» location cá»§a cÆ¡ quan, trá»¥ sá»Ÿ, chi nhÃ¡nh
           - Cáº§n thÃ´ng tin Ä‘á»‹a danh, Ä‘á»‹nh vá»‹
           - CÃ¢u há»i vá» chia tÃ¡ch/sÃ¡p nháº­p Ä‘Æ¡n vá»‹ hÃ nh chÃ­nh (tá»‰nh, huyá»‡n, xÃ£)
           - Follow-up questions vá» Ä‘á»‹a danh/Ä‘Æ¡n vá»‹ hÃ nh chÃ­nh (VD: "Tháº¿ cÃ²n tá»‰nh X thÃ¬ sao?")
           
        3. Route Ä‘áº¿n "rephrase_question" cho Táº¤T Cáº¢ cÃ¡c trÆ°á»ng há»£p khÃ¡c:
           - CÃ¢u há»i vá» thá»§ tá»¥c hÃ nh chÃ­nh chung
           - CÃ¢u há»i thÃ´ng tin, tÆ° váº¥n
           - Má»i cÃ¢u há»i khÃ´ng rÃµ rÃ ng thuá»™c 2 category trÃªn
        </constraint>

        <input>
        CÃ¢u há»i HIá»†N Táº I cáº§n phÃ¢n tÃ­ch: "{raw_question}"
        
        Ngá»¯ cáº£nh há»™i thoáº¡i (Ä‘á»ƒ hiá»ƒu follow-up questions): {conversation_history}
        
        LÆ¯U Ã: Náº¿u cÃ¢u há»i hiá»‡n táº¡i lÃ  follow-up (nhÆ° "Tháº¿ cÃ²n X thÃ¬ sao?"), hÃ£y káº¿t há»£p vá»›i ngá»¯ cáº£nh Ä‘á»ƒ hiá»ƒu intent Ä‘áº§y Ä‘á»§.
        </input>
        
        <output>
        Dá»±a trÃªn phÃ¢n tÃ­ch cÃ¢u há»i HIá»†N Táº I, tráº£ vá» CHÃNH XÃC má»™t trong:
        - "autofill_agent"
        - "geoadmin_agent" 
        - "rephrase_question"
        </output>
        """

        # Limit conversation history Ä‘á»ƒ trÃ¡nh bias quÃ¡ nhiá»u
        conversation_history = state.get('conversation_history', [])
        # Chá»‰ láº¥y 2-3 turns gáº§n nháº¥t Ä‘á»ƒ cÃ³ context nhÆ°ng khÃ´ng bá»‹ overwhelm
        limited_history = conversation_history[-6:] if len(conversation_history) > 6 else conversation_history
        # print("Conversation History", limited_history)
        prompt = PROMPT.format(
            raw_question=state.get('raw_question', ''),
            conversation_history=limited_history if limited_history else "KhÃ´ng cÃ³ lá»‹ch sá»­ há»™i thoáº¡i"
        )

        response = self.request.app.state.litellm_service.process(
            LiteLLMInput(
                messages=[
                    CompletionMessage(
                        role=Role.SYSTEM,
                        content="Báº¡n lÃ  má»™t router agent thÃ´ng minh. PhÃ¢n tÃ­ch cÃ¢u há»i hiá»‡n táº¡i vÃ  tham kháº£o ngá»¯ cáº£nh khi cáº§n thiáº¿t Ä‘á»ƒ hiá»ƒu follow-up questions. ÄÆ°a ra quyáº¿t Ä‘á»‹nh routing chÃ­nh xÃ¡c dá»±a trÃªn intent tháº­t sá»± cá»§a user."
                    ),
                    CompletionMessage(
                        role=Role.USER,
                        content=prompt
                    )
                ],
                reasoning_effort="medium",
            )
        )

        # Parse response Ä‘á»ƒ láº¥y routing decision
        next_action = response.response.strip().replace('"', '').replace("'", "")
        
        # Validate routing decision
        valid_routes = ["autofill_agent", "geoadmin_agent", "rephrase_question"]
        if next_action not in valid_routes:
            next_action = "rephrase_question"  # Default fallback
            
        print(f"ğŸ”€ LLM Router decision for '{state.get('raw_question', '')[:50]}...': {next_action}")
        print(f"ğŸ“ Limited conversation history length: {len(limited_history)}")
        return next_action

        
    async def gather_refined_contexts(self, state: ChatbotState) -> dict[str, Any]:
        # Create semaphore to limit concurrent requests
        semaphore = asyncio.Semaphore(5)
        
        async def process_sub_question(sub_question: str) -> str:
            async with semaphore:
                # Use ainvoke directly since it's async
                result = await self.sub_agent.compiled_graph.ainvoke(
                    SubAgentState(
                        sub_question=sub_question,
                        raw_context="",
                        refined_context="",
                        references=[],
                    )
                )
                if result and 'refined_context' in result and 'references' in result:
                    return result['refined_context'], result['references']
                return "", []

        # Process all sub-questions concurrently with semaphore control
        tasks = [process_sub_question(sub_question) for sub_question in state['sub_questions']]
        results = await asyncio.gather(*tasks)
        
        # Filter out empty results
        refined_contexts = [result[0] for result in results if result]
        references = [ref for result in results for ref in result[1]]

        return {
            "refined_contexts": refined_contexts,
            "references": references
        }
            
    @property
    def compiled_graph(self) -> StateGraph:
        graph = StateGraph(ChatbotState)
        for key, tool in self.nodes.items():
            graph.add_node(key, tool)
            
        def route_rephraser(state: ChatbotState) -> Literal["decompose_question", "direct_answer"]:
            need_rag = state.get('need_rag', False)
            if need_rag:
                return "decompose_question"
            else:
                return "direct_answer"
        
        graph.add_edge(START, "conversation_history")
        graph.add_conditional_edges(
            "conversation_history",
            self.route_agent,
        )
        
        # Edges tá»« cÃ¡c agent Ä‘áº¿n END
        graph.add_edge("autofill_agent",  "profile_agent")
        graph.add_edge("profile_agent", END)
        graph.add_edge("geoadmin_agent", END)

        # Flow cho rephrase_question
        graph.add_conditional_edges(
            "rephrase_question",
            route_rephraser,
        )
        graph.add_edge("decompose_question", "sub_agent")
        graph.add_edge("sub_agent", "answer_aggregator")
        graph.add_edge("direct_answer", END)
        graph.add_edge("answer_aggregator", END)
        
        return graph.compile()

    async def run(self, input: ChatbotApplicationInput, background_tasks: BackgroundTasks) -> ChatbotApplicationOutput:
        result = await self.compiled_graph.ainvoke(
            ChatbotState(
                raw_question=input.raw_question,
                rephrased_question="",
                sub_questions=[],
                answer="",
                conversation_history=[],
                refined_contexts=[],
                references=[],
                detected_fields={},
                filled_profile_info={},
            )
        )
        background_tasks.add_task(
            self.memory_service.save_conversation_history,
            input.raw_question,
            result.get('rephrased_question', ''),
            result.get('sub_questions', []),
            result.get('answer', ''),
        )


        return ChatbotApplicationOutput(
            raw_question=input.raw_question,
            rephrased_question=result.get('rephrased_question', ''),
            sub_questions=result.get('sub_questions', []),
            answer=result.get('answer', ''),
            refined_contexts=result.get('refined_contexts', []),
            references=list(set(result.get('references', []))),
            filled_profile_info=result.get('filled_profile_info', {}),
            detected_fields=result.get('detected_fields', {})
        )